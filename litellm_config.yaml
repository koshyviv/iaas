model_list:
  - model_name: local-llama3.2
    litellm_params:
      model: ollama/llama3.2:1b
      api_base: http://ollama:11434

litellm_settings:
  # Send traces to Langfuse
  success_callback: ["langfuse"]
  failure_callback: ["langfuse"]

# Optional server settings
router_settings:
  num_retries: 1
  timeout: 120


